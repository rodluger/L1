{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import matplotlib.pyplot as pl\n",
    "from tqdm import tqdm\n",
    "import celeriteflow as cf\n",
    "import keras\n",
    "keras.backend.set_floatx(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetTestData(clobber=False):\n",
    "    \"\"\"Get test data.\"\"\"\n",
    "    data = np.load(\"data/c6/test_data.npz\")\n",
    "    reg_fluxes = data['reg_fluxes']\n",
    "    reg_pixels = data['reg_pixels']\n",
    "    reg_npix = data['reg_npix']\n",
    "    time = data['time']\n",
    "    flux = data['flux']\n",
    "    flux_err = data['flux_err']\n",
    "    return time, reg_fluxes, reg_pixels, reg_npix, flux, flux_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–Œ         | 29/500 [00:19<05:22,  1.46it/s]"
     ]
    }
   ],
   "source": [
    "# Grab the data\n",
    "time, reg_fluxes, reg_pixels, reg_npix, flux, flux_err = GetTestData()\n",
    "ntime = flux.shape[0]\n",
    "nreg = reg_fluxes.shape[0]\n",
    "\n",
    "# Set up tensorflow\n",
    "import tensorflow as tf\n",
    "dtype = tf.float64\n",
    "\n",
    "# Tweakable stuff\n",
    "logjitter0 = np.log(0.01)  # Initial log jitter\n",
    "l0 = 1e-2  # Initial L2 regularization variance\n",
    "learning_rate = 1e-2  # Initial Adam learning rate\n",
    "niter = 500  # Number of iterations\n",
    "P0 = 10.0  # Period guess\n",
    "H = 2  # Dimension of the hidden layer\n",
    "\n",
    "# This is our data we want to fit\n",
    "y = tf.constant(flux - 1.0, dtype=dtype)\n",
    "\n",
    "# This is the data uncertainty\n",
    "y_err = tf.constant(flux_err, dtype=dtype)\n",
    "\n",
    "# Compute weakly regularized max like solution as a guess\n",
    "X = reg_fluxes.T - 1.0\n",
    "L = np.diag(np.ones(nreg) * l0 ** 2)\n",
    "LXT = np.dot(L, X.T)\n",
    "S = np.dot(X, np.dot(L, X.T))\n",
    "S += np.diag(flux_err ** 2 + np.exp(2 * logjitter0))\n",
    "Sinvy = np.linalg.solve(S, (flux - 1.0)[:, None])\n",
    "wguess = np.dot(LXT, Sinvy)\n",
    "\n",
    "# Keras NN model\n",
    "nn = keras.Sequential()\n",
    "nn.add(keras.layers.Dense(H, activation=\"softmax\", input_dim=nreg))\n",
    "nn.add(keras.layers.Dense(1))\n",
    "feed_dict = {nn.input: reg_fluxes.T - 1.0}\n",
    "model = tf.squeeze(nn.output)\n",
    "\n",
    "# Celerite GP\n",
    "logjitter = tf.Variable(logjitter0, dtype=dtype)\n",
    "t = tf.constant(time, dtype=dtype)\n",
    "diag = y_err ** 2 + tf.exp(2*logjitter)\n",
    "resid = y - model\n",
    "log_S0 = tf.Variable(np.log(np.var(flux)), dtype=dtype)\n",
    "log_w0 = tf.Variable(np.log(2 * np.pi / P0), dtype=dtype)\n",
    "log_Q = tf.Variable(0.0, dtype=dtype)\n",
    "kernel = cf.terms.SHOTerm(log_S0=log_S0,\n",
    "                          log_w0=log_w0,\n",
    "                          log_Q=log_Q)\n",
    "gp = cf.GaussianProcess(kernel, t, resid, diag)\n",
    "loglike = gp.log_likelihood\n",
    "\n",
    "# Losses\n",
    "l = tf.constant(l0, dtype=dtype)\n",
    "loss = -2 * loglike\n",
    "for w in nn.trainable_weights:\n",
    "    loss += (1 / l) * tf.reduce_sum(tf.abs(w))\n",
    "opt = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "# Init session\n",
    "session = tf.get_default_session()\n",
    "if session is None:\n",
    "    session = tf.InteractiveSession()\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "# Assign initial guess for the weights\n",
    "w1_0 = 1e-6 * np.random.randn(nreg, H)\n",
    "w1_0[:, 0] = wguess[:, 0]\n",
    "w2_0 = 1e-6 * np.random.randn(H, 1)\n",
    "w2_0[0, 0] = 1\n",
    "session.run(tf.assign(nn.layers[0].kernel, w1_0))\n",
    "session.run(tf.assign(nn.layers[0].bias, 0 * np.random.randn(H)))\n",
    "session.run(tf.assign(nn.layers[1].kernel, w2_0))\n",
    "session.run(tf.assign(nn.layers[1].bias, [-0.5]))\n",
    "\n",
    "# Plot initial model\n",
    "model0 = model.eval(feed_dict=feed_dict)\n",
    "fig, ax = pl.subplots(2)\n",
    "ax[0].set_title(\"Final model\")\n",
    "ax[0].plot(time, flux - 1, 'k.', ms=2, alpha=0.3)\n",
    "ax[0].plot(time, model0, 'r-', lw=0.5)\n",
    "\n",
    "# Iterate!\n",
    "losses = np.zeros(niter)\n",
    "best_loss = np.inf\n",
    "for i in tqdm(range(niter)):\n",
    "    session.run(opt, feed_dict=feed_dict)\n",
    "    losses[i] = loss.eval(feed_dict=feed_dict)\n",
    "    if losses[i] < best_loss:\n",
    "        best_loss = losses[i]\n",
    "        best_weights = session.run(nn.trainable_weights)\n",
    "        best_logjitter = logjitter.eval()\n",
    "        best_log_S0 = log_S0.eval()\n",
    "        best_log_w0 = log_w0.eval()\n",
    "        best_log_Q = log_Q.eval()\n",
    "session.run([\n",
    "    tf.assign(a, b) for a, b in zip(nn.trainable_weights, best_weights)])\n",
    "session.run(tf.assign(logjitter, best_logjitter))\n",
    "session.run(tf.assign(log_S0, best_log_S0))\n",
    "session.run(tf.assign(log_w0, best_log_w0))\n",
    "session.run(tf.assign(log_Q, best_log_Q))\n",
    "\n",
    "# Log\n",
    "print(\"GP stuff:\", best_logjitter, best_log_S0, best_log_w0, best_log_Q)\n",
    "\n",
    "# Plot learning rate\n",
    "fig, ax = pl.subplots(1)\n",
    "ax.plot(range(niter), losses)\n",
    "\n",
    "# Plot weights\n",
    "'''\n",
    "for w in best_weights:\n",
    "    fig, ax = pl.subplots(1)\n",
    "    ax.imshow(np.log10(np.abs(w)), aspect='auto')\n",
    "'''\n",
    "\n",
    "# Plot initial model\n",
    "'''\n",
    "fig, ax = pl.subplots(2)\n",
    "ax[0].set_title(\"Initial model\")\n",
    "ax[0].plot(time, flux, 'k.', ms=2, alpha=0.3)\n",
    "ax[0].plot(time, 1 + model0, 'r-', lw=0.5)\n",
    "ax[1].plot(time, flux - model0, 'k.', ms=2, alpha=0.3)\n",
    "'''\n",
    "\n",
    "# Plot final model\n",
    "fig, ax = pl.subplots(2)\n",
    "ax[0].set_title(\"Final model\")\n",
    "ax[0].plot(time, flux, 'k.', ms=2, alpha=0.3)\n",
    "ax[0].plot(time, 1 + model.eval(feed_dict=feed_dict), 'r-', lw=0.5)\n",
    "ax[1].plot(time, flux - model.eval(feed_dict=feed_dict), 'k.', ms=2, alpha=0.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
